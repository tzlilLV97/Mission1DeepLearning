{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tzlilLV97/Mission1DeepLearning/blob/main/fridayfriday.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alon Feldman 312213135\\\n",
        "Tzlil lev-or 2222222**\n"
      ],
      "metadata": {
        "id": "pOrE-XnbScNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1. Data\n"
      ],
      "metadata": {
        "id": "IKvCf42E1sWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "tnzwyismSfzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/My Drive/YearPredictionMSD.txt.zip' # TODO - UPDATE ME WITH THE TRUE PATH!\n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "metadata": {
        "id": "B7q2zSpNTByM",
        "outputId": "fe7fc652-8523-41c9-ace7-8b655eaba7c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vOklsaAiTNqD",
        "outputId": "ea62ca17-e2e5-466e-d27d-84e52b5f702e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d10b6fdf-3a3e-452f-88f7-cf6bf5329b97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d10b6fdf-3a3e-452f-88f7-cf6bf5329b97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d10b6fdf-3a3e-452f-88f7-cf6bf5329b97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d10b6fdf-3a3e-452f-88f7-cf6bf5329b97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "metadata": {
        "id": "ztx1Q_LQUY_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(20)"
      ],
      "metadata": {
        "id": "hqXflAwCUbsg",
        "outputId": "eb5073b4-f990-4ea1-dedc-cbfa4bb71caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e023d5f-cc3d-49dc-ab28-94b02e1c7d79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e023d5f-cc3d-49dc-ab28-94b02e1c7d79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e023d5f-cc3d-49dc-ab28-94b02e1c7d79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e023d5f-cc3d-49dc-ab28-94b02e1c7d79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (a)"
      ],
      "metadata": {
        "id": "sHoe8mA0Uz5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Write your explanation here\n",
        "# like overfitting- in Tzlil notebook -  ×œ×”×¡×‘×™×¨ ×©×™×”×™×” ×ª×œ×•×ª (×ž×™×“×¢ ×”×“×“×™) ×‘×™×Ÿ ×©×™×¨×™× ×©×•× ×™× ×©×œ ××•×ª×• ×”×–×ž×¨"
      ],
      "metadata": {
        "id": "JqiNiGUaU1cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (b)"
      ],
      "metadata": {
        "id": "lsukPuC8Yha3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "metadata": {
        "id": "MOkd5CMfYiYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your explanation here\n",
        "# to make them from the same distrabtion - Tzlil notebook - ×œ×”×¡×‘×™×¨ ×©×× ××™×ž× ×• ××ª ×”×ž×©×§×•×œ×•×ª ×œ×¤×™ × ×¨×ž×•×œ ×ž×¡×•×™×™× ××– × ×¨×¦×” ×œ× ×¨×ž×œ ××ª ×”×ž×™×“×¢ ×©× ×©×¢×¨×š ×œ×¤×™ ××•×ª×• × ×¨×ž×•×œ"
      ],
      "metadata": {
        "id": "AOHt6XF2aCOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (c)"
      ],
      "metadata": {
        "id": "FKdAqgQ7eqIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Write your explanation here\n",
        "# do make sure it is still \"independence new data\"- Tzlil notebook"
      ],
      "metadata": {
        "id": "wG_4Sbi0esx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Classification\n"
      ],
      "metadata": {
        "id": "ynOtihr72ddI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  e=0.00001 #To avoid log(0)=-inf\n",
        "  cross_entropy=  return -t * np.log(y+e) - (1 - t) * np.log(1 - y+e)\n",
        "\n",
        "  return cross_entropy\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "metadata": {
        "id": "XzNzrSNaibT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (a) \n"
      ],
      "metadata": {
        "id": "YYDeM0O0i-b_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Your code goes here \n",
        "  return sigmoid(np.dot(X,np.transpose(w))+b)\n",
        "\n",
        "pred(np.zeros(90), 1, np.ones([2, 90]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjE6mYM2jAup",
        "outputId": "f1c2bc4f-8314-4eb4-92e6-9f6641df477e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.73105858, 0.73105858])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (b) "
      ],
      "metadata": {
        "id": "DxEBZxbx28fm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Your code goes here\n",
        "  N=len(y)\n",
        "  error=y-t\n",
        "  dLdw=1/N*np.dot(np.transpose(X),error)\n",
        "  dLdb=np.mean(error)\n",
        "  return (dLdw,dLdb)\n"
      ],
      "metadata": {
        "id": "QVurFjyNlfwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\\begin{align}\n",
        "        &\\frac{\\partial C}{\\partial w_j}=\\frac{\\partial C}{\\partial \\sigma}\\frac{\\partial \\sigma}{\\partial z}\\frac{\\partial z}{\\partial w_j} \\\\\n",
        "        &C=\\frac{1}{N}\\sum_{i=1}^N-t_i\\cdot log(\\sigma_i)-(1-t_i)\\cdot log(1-\\sigma_i)\\\\\n",
        "        &\\sigma_i=sigmoid(z_i)\\\\\n",
        "        &z_i=w^T\\cdot x_i+b\\\\\n",
        "        &\\frac{\\partial C}{\\partial \\sigma}=\\frac{1}{N}\\sum_{i=1}^N\\frac{\\sigma(z)-t}{\\sigma(z)(1-\\sigma(z))}\\\\\n",
        "        &\\frac{\\partial \\sigma}{\\partial z}=\\sigma(z)(1-\\sigma(z))\\\\\n",
        "        &\\frac{\\partial z}{\\partial w_j}=x^j â†’\\text{ the j feature of sample x}\\\\\n",
        "        &\\frac{\\partial C}{\\partial w_j}=(\\sigma(z)-t) \\cdot x^j \\\\\n",
        "        &\\text{For $\\frac{\\partial C}{\\partial b}$ we get  the mean error i.e $error_i=\\sigma(z_i)-t_i$}\\\\\n",
        "        &\\text{And $\\frac{\\partial C}{\\partial b}=\\frac{1}{N}\\sum_{i=1}^Nerror_i$}\\\\\n",
        "        &\\text{Finally in Vector Form:}\\\\\n",
        "        &\\frac{\\partial C}{\\partial w}=\\frac{1}{N}X^T\\cdot \\vec{error}\n",
        "    \\end{align}"
      ],
      "metadata": {
        "id": "4kIEa0OAtKBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (c)\n",
        " $\\frac{\\partial\\mathcal{L}}{\\partial b}$"
      ],
      "metadata": {
        "id": "LBor468S5QzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n",
        "b=1\n",
        "h=0.00001\n",
        "X=np.ones([2, 90])\n",
        "y=pred(np.zeros(90), b, X)       #this is for x in f(x)\n",
        "y_h=pred(np.zeros(90), b+h, X)   #this is for x+h f(x+h)\n",
        "t=np.ones(2)\n",
        "\n",
        "r1 = (cost(y_h,t)-cost(y,t))/h      #f(x+h)-f(x)/h\n",
        "_,r2 = derivative_cost(X,y,t)\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6-8WJb_1_pm",
        "outputId": "3ab51297-7960-4189-bfbd-5a1d49b568fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - -0.26892791236410307\n",
            "The algorithm results is -  -0.2689414213699951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (d)\n",
        " $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$"
      ],
      "metadata": {
        "id": "a114_YlZ5Tj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here. You might find this below code helpful: but it's\n",
        "# up to you to figure out how/why, and how to modify the code\n",
        "b=1\n",
        "w=np.zeros(90)\n",
        "h=0.0001\n",
        "X=np.ones([2, 90])\n",
        "y=pred(w, b, X)       #this is for x in f(x)\n",
        "t=np.ones(2)\n",
        "r1=np.zeros(90)\n",
        "for i in range(90):\n",
        "  w[i]+=h\n",
        "  y_h=pred(w, b, X)   #this is for x+h f(x+h)\n",
        "  w[i]-=h\n",
        "  r1[i] = (cost(y_h,t)-cost(y,t))/h      #f(x+h)-f(x)\n",
        "\n",
        "r2,_ = derivative_cost(X,y,t)\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKIRzSh45VeM",
        "outputId": "ee25fd54-fc80-459a-90d6-8f7f462a520d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - [-0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791\n",
            " -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791 -0.26892791]\n",
            "The algorithm results is -  [-0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142\n",
            " -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142 -0.26894142]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (e)"
      ],
      "metadata": {
        "id": "nbJvDDyUO3iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_gradient_descent(w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  train_xs=train_xs1\n",
        "  train_ts=train_ts1\n",
        "  train_norm_xs=train_norm_xs1\n",
        "  iter = 0\n",
        "  running_cost=[]\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set (there is code above for how to do this)\n",
        "    reindex = np.random.permutation(len(train_xs))\n",
        "    train_xs = train_xs[reindex]\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute the prediction\n",
        "      y=pred(w,b,X)\n",
        "      # update w and b\n",
        "      dLdw , dLdb = derivative_cost(X,y,t)\n",
        "      b=b-mu*dLdb\n",
        "      w=w-mu*dLdw\n",
        "    # increment the iteration count\n",
        "    iter += 1\n",
        "    # compute and print the *validation* loss and accuracy\n",
        "    if (iter % 10 == 0):\n",
        "      val_y=pred(w,b,val_norm_xs)\n",
        "      val_cost = cost(val_y,val_ts)\n",
        "      val_acc = get_accuracy(val_y,val_ts)\n",
        "      running_cost.append(val_cost)\n",
        "      print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (iter, val_acc * 100, val_cost))\n",
        "\n",
        "    if iter >= max_iters:\n",
        "      break\n",
        "\n",
        "    # Think what parameters you should return for further use\n",
        "  \n",
        "  return w,b,running_cost,val_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiFFp-kVPooz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (f)\n"
      ],
      "metadata": {
        "id": "FXAtiBuVhwoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n",
        "mu=[0.001,0.2,0.5,5,15] #check for 5 value of mu\n",
        "run_cost=[[] for i in range(len(mu))] #array to save the learning process\n",
        "for m in range(len(mu)):  #for each learning rate mu, run gradient descent and save the learning cosr process\n",
        "  _,_,costRun,accRun=run_gradient_descent(w0,b0,mu=mu[m])\n",
        "  run_cost[m]=costRun\n",
        "\n",
        "#plot resulte\n",
        "for m in range(len(mu)):\n",
        "  plt.plot([10*i for i in range(len(run_cost[m]))],run_cost[m])\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.legend(mu)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1BxxdyuhwZP",
        "outputId": "9507712c-f512-452f-9ffd-8f7b7692d030"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 10. [Val Acc 71%, Loss 0.991670]\n",
            "Iter 20. [Val Acc 73%, Loss 0.870124]\n",
            "Iter 30. [Val Acc 73%, Loss 0.858341]\n",
            "Iter 40. [Val Acc 73%, Loss 0.858172]\n",
            "Iter 50. [Val Acc 74%, Loss 0.856827]\n",
            "Iter 60. [Val Acc 74%, Loss 0.857416]\n",
            "Iter 70. [Val Acc 74%, Loss 0.857661]\n",
            "Iter 80. [Val Acc 74%, Loss 0.857764]\n",
            "Iter 90. [Val Acc 74%, Loss 0.857195]\n",
            "Iter 100. [Val Acc 74%, Loss 0.857996]\n",
            "Iter 10. [Val Acc 73%, Loss 0.874679]\n",
            "Iter 20. [Val Acc 73%, Loss 0.870297]\n",
            "Iter 30. [Val Acc 73%, Loss 0.873979]\n",
            "Iter 40. [Val Acc 73%, Loss 0.887878]\n",
            "Iter 50. [Val Acc 73%, Loss 0.880170]\n",
            "Iter 60. [Val Acc 73%, Loss 0.876760]\n",
            "Iter 70. [Val Acc 72%, Loss 0.893191]\n",
            "Iter 80. [Val Acc 73%, Loss 0.869019]\n",
            "Iter 90. [Val Acc 73%, Loss 0.879380]\n",
            "Iter 100. [Val Acc 73%, Loss 0.855958]\n",
            "Iter 10. [Val Acc 72%, Loss 0.895031]\n",
            "Iter 20. [Val Acc 70%, Loss 0.895556]\n",
            "Iter 30. [Val Acc 72%, Loss 0.909215]\n",
            "Iter 40. [Val Acc 72%, Loss 0.917202]\n",
            "Iter 50. [Val Acc 72%, Loss 0.903796]\n",
            "Iter 60. [Val Acc 70%, Loss 0.940046]\n",
            "Iter 70. [Val Acc 72%, Loss 0.917361]\n",
            "Iter 80. [Val Acc 71%, Loss 0.902108]\n",
            "Iter 90. [Val Acc 72%, Loss 0.896776]\n",
            "Iter 100. [Val Acc 71%, Loss 0.888653]\n",
            "Iter 10. [Val Acc 66%, Loss 2.441023]\n",
            "Iter 20. [Val Acc 65%, Loss 3.038000]\n",
            "Iter 30. [Val Acc 69%, Loss 3.124655]\n",
            "Iter 40. [Val Acc 64%, Loss 2.992779]\n",
            "Iter 50. [Val Acc 67%, Loss 2.644641]\n",
            "Iter 60. [Val Acc 58%, Loss 3.880935]\n",
            "Iter 70. [Val Acc 58%, Loss 3.316270]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain and discuss your results here:**\n",
        " $$$$\n",
        "As we see, for too small learning rate ($\\mu=0.001$) the convergence is  very slow, almost can't be seen at the graph. $$$$\n",
        "For too large learning rate ($\\mu=5,15$) there is no convergence - it's not even monotonic. $$$$\n",
        "For good value of learning rate ($\\mu=0.2,0.5$) we can see fast and good convergence.$$$$\n",
        "![download.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gU1frA8e/Z3Wx6L4QkhAQCgQChhWaliKgIKiKgomLH3q/lWn567QUrV/RaQEEQEERUUFBBESkJJUAoAQKkkt7blvP7YwMkIUAg25Kcz/PMk83uzJl3N5t558ycIqSUKIqiKO2XxtEBKIqiKI6lEoGiKEo7pxKBoihKO6cSgaIoSjunEoGiKEo7p3N0AGcrKChIRkVFOToMRVGUViUpKSlfShnc1GutLhFERUWRmJjo6DAURVFaFSHE4VO9pi4NKYqitHMqESiKorRzKhEoiqK0cyoRKIqitHMqESiKorRzKhEoiqK0cyoRKIqitHPtJhFUltby18J9mAxmR4eiKIriVNpNIshKLSb59wxWfbELs1nNwaAoinJMu0kEMQNDuOC6bhzYmseaeXtQE/IoiqJY2DwRCCG0QoitQogfm3jNVQjxrRBivxBioxAiypax9B3ViYQrotj9dzbrlxxQyUBRFAX7jDX0ELAb8GnitduBIilljBBiCvAGMNmWwQweF01NhYFtq47g5qlj4GVRttydoiiK07NpjUAIEQGMBT47xSpXAXPqHi8GRgkhhI1j4sLJ3ek2qAMbvj/Izj8zbbk7RVEUp2frGsF7wL8A71O8Hg6kA0gpjUKIEiAQyK+/khDiLuAugMjIyBYHJTSCUdN6UlttZO38vbh66OiW0KHF5SqKorRGNqsRCCGuBHKllEktLUtK+amUMkFKmRAc3ORw2mdNq9Vw2Z29CYvxY/WXKRzeVWCVchVFUVobW14aOh8YL4Q4BCwARgoh5jZaJxPoBCCE0AG+gN2OyDq9livujScgzJOVs3aQvb/YXrtW6hTlVFBVXuvoMBTllMxm2eabnNssEUgpn5ZSRkgpo4ApwO9SyqmNVvsBuKXu8cS6dez6ibu66xj3QD+8Atz4cWYy+Rll9tx9uyWlJPmPdBa8tIkFL20i+0CJo0NSlJOU5FUx/8WN/PD+tjadDOzej0AI8ZIQYnzdr58DgUKI/cCjwFP2jgfAw0fP+If6oXfT8sMH2ynOrXREGO2GsdbEb7N389e3qUT0DEDnquX7GVtIWZfl6NAU5bi8I2V891YS5UXVZO4tYsvKU07w1eqJ1taWPiEhQdpqqsqinAqWvL0FF1ctEx4fiJe/q032056V5lex4pMd5GeUM/jKaBIuj6Kmysivn+8iPaWQ3heHc8Gkbmi17aavo+KE0vcUsmLWDlw9LFcMEn8+xP6kXCY8MYDQaF9Hh3dOhBBJUsqEpl5T/231+Id6Mu6BvlRXGPjhg21UlxscHVKbkr67kEWvJVKaX83Ye+MZNDYaoRG4ebpw5f196T86kp1rM/nhvW1Ulqr7BopjpG4+yo8fbsc7wI1rn0ggoKMnF1/fHS8/V1Z9kUJttdHRIVqdSgSNhHT2Yew98ZTmVbH8o+1t8o9ub1JKtvxymOUfbMPDV891TycQ1SeowToajeC8a2O45NY4jh4qZdHrm8k7ou7XKPa1/bd0fv18F6FdfJnw+IDjVwVcPVy45NY4yvKr+GthqoOjtD6VCJoQHuvPmDt7kXekjJ8/3oHRYHJ0SK1WbbWRX/63k3+WHqDrgBCu/ddA/EI8Trl+7JBQJjw+ACQseSuJfZtz7Bit0l5JKfln6X7WLUqlS/9gxj3YF1cPlwbrhHXzY+DlUexZn83+pFwHRWobKhGcQnTfYEbd3IPMvUX8+tkuzCY1fPXZKj5ayeI3kji4NY/zJsRw6R290LuduQ9jSGcfrnt6EMGdvVn1eQrrl+xv0y02FMcymcz8Nmc3W345Qq+LwhlzZ290Ltom100YG0VIlA9r5u2hrLDazpHajkoEpxE7tCMXTOpG2vZ8/pi7B6kORs2WlpzPotc2U1Vay7iH+tH/0kjOZvQQDx89Vz3cn94XhbP11yP8NHM71RXqno1iXYYaEz//dwd7N+QweFw0F1/fHY3m1N9TrVbD6NviMJskq79MaTMnKCoRnEHfkZ0YdGU0e/7J4e/v9qsRS89AmiUblx/k5/8m4xviwXXPJNCpR8A5laXVabj4hliG3xhLxp4iFr+eSGFWhZUjVtqrqvJavn93K+kpBQy/MdbSeKEZJyt+IR5cOLk7WanFbFt1xA6R2p49Rh9t9QaNjaKmwsD239Jx83Qh4YooR4fklGoqDaz6MoXDOwroMSyUi6+PRadvuop9NnpdGE5AR09WfLqTxW8kcsmtcXTpZ52hRpT2qTS/iuUfbqessJrL7u5z1t+nHsNCObyzgI3LDhLRw5+Qzk0Nrtx6qBpBMwghuOC6bsQOCWXjDwfZsSbD0SE5nYLMcha9lkj6rkIumtKdkTf3tEoSOKZjjB+Tnk7AP9SDFbN2sPmnNHWpTjkn+RllfPdmElVltVz1UL9zOqkQQjD8xlg8fPWs+iIFQ03rblCiEkEzCY1gxM09iIoP4s9v97Fvk2rNckxq4lEWv5mEocbE1Y/2p8/wiLO6H9BcXv5uXPPYAGKHhLJpeRorP92pmvcqZyVjbxFL396CRiu45vEBdIzxO+ey3DxduGRaHMW5laxb1LqblKpEcBa0Wg1j7uxFeDc/fpu9m0M78s+8URtmNpn5+7v9/PrZLoLCvZj070Et+sdqDp1ey6hpPTl/Ygxp2/P47s0kSvLUkCDKme1PymX5h9vw9HdjwhMDCQzzanGZ4bH+DLi0Mynrsji4Nc8KUTqGSgRnSeei5Yp74gmM8GLlpzvJSm2fI5ZWldey/MPtbFt1hN4Xh3P1o/3x9LXPkBxCCPpdEsm4B/tRUVxjuSSVUmiXfSutU/IfGfzy2U46RPkw4fEBeAe4Wa3sweOiCY705ve5uykvqrFaufakEsE50LvrGPdAX3wC3fhp5vZ21wM293ApC1/dTPb+Ekbe3JOLr49Fq7P/V6lTzwCuezoBTz9Xln+4jW2rj6hWXUoDUko2fH+Av77dR3R8EOMf7Iebp8uZNzwLWp2lSanJYOa3OSmt8t6VSgTnyN1bz7gH+6H30LH8w20UH20flyf2/JPNkre2gIQJTwyg53kdHRqPb7AH1/5rINH9gvl78X5Wz07BWNu6b9wp1mE2mfn96z0krTxM3IVhXHZXb6s2YKjPP9STC67rRsaeIrb9lm6TfdiSSgQt4B3gxlUP9Qdg2ftb21RPw8ZMRjN/zt/Lb3N2E9rVl0nPDHKaJnN6Nx2X3dmbweOi2bfxKEve3tKm/xbKmRlqTfw8awd71mczaGwUw2+IRWPjEW3jLgijS79gNnx/gLz01nWVQCWCFvLr4MG4B/pRW2lk+QfbqCpre6NmVpTUsOzdrexYm0m/0ZGMf7Av7t56R4fVgNAIBo2N5op7+lCcW8mi1zaTpWaca5eqyw0se3crR3YWcPENsQwe18UmrdgaE0IwYmoP3L1cWPX5LgytqGaqEoEVBEd6M/a+vpQWVLP8w+3UVrWdJo3ZB0pY+Opm8tLLuPSOXpx/bYzNz6xaIrpvMBOfTEDvrmPZu1vZ+Wemo0NS7Ki0oIrv3koiP72cy+7qQ++Lwu26fzcvF0ZNi6Mop5L1i/fbdd8t4bz/0a1MWDc/LrurNwUZ5fz8cXKrH7FUSsmONRl8P2MLOr2WiU8m0C2hg6PDapaAjp5c91QCET38WfvNXtbM24PJqAYNbOsKMstZUtdRbPxD/ejS3zG9zzv1DKDfJZ3Y+Wcmacmto4m5SgRWFNUniFHTepKZWswv/2u9I5YaDSZ+/2o3fy7YR6eeAUx6OoHA8Ja3ubYnVw8Xxt7XlwFjItn1VxbL3tuqJrtpwzL3FbHk7S0gBNc8NoCwbrbtz3ImQ6/qSlAnL37/ajcVJc7fpFQlAivrPjiUiyZ351ByPr9/3fpGLC0rrGbJW1vY808OCWOjGHtv/EnjsrcWGo1g2DUxjL49jrzDZSx6bTO5h0sdHZZiZQe25LL8g+14+uq59l8DneKkReuiYfRtvTDUmPh9zm6nPw6oRGADfYZHMGR8NHs35LBuUWqraduesaeQha9upiS3kivu6cOQcV0QpxmSt7XoPiiUCU8MBAFL3t7C3o1qeJC2YufaDFb+byfBkV5MeHygVTuKtVRAR08umBjDkZRCkv9w7vHJbJYIhBBuQohNQojtQohdQogXm1hnmhAiTwixrW65w1bx2NvAy6PoO6oTyX9kkPjzIUeHc1pSSrauOsIP72/D3cuFiU8lEN23bY3uGRzpzaSnB9EhyofVX6awbnFqq710p1i+sxt/OMja+fuI6h3I+If74+blfDXXXheFExUfxPql+8nPKHd0OKdkyxpBDTBSStkX6AdcJoQY2sR630op+9Utn9kwHrsSQnD+tTH0GGYZIC35D+fsZGKoMfHr57tY/91+uvQLZuJTCfiHejo6LJtw99Yz/uF+9Lk4nO2r0/nxIzXZTWtkNplZM3cPiT8foud5Hbl8eh9cbNRRrKWEEIy8qQeuHi6s+mKX03Z2tFkikBbHUqBL3dI6rpFYidBY2hVH9w3ir29Tne6SRHFuJYvfSORAUi7DrunKmLt6N2sqydZMq9Vw0fWxjJjag8x9xSx6bTMFmc57pqY0ZKg1seKTnaT8nU3CFVGMuKmHUzdnBssJyKhbelKYVcH6pQccHU6TbPpfL4TQAklADDBTSrmxidWuFUJcBOwDHpFSnnTqLIS4C7gLIDIy0oYRW59Gq+HSO3rx40fJ/DZnN3p3HdHxQVbfjzRLjEYzxhoThloTxhozRoMJQ40JY63Z8tNgqnvdTG2V0TKvgoBxD/SjU9y5zSLWWsVdEEZAmCcrZu1g8ZtJXDKtJ137hzg6LOU0qisM/DQzmZy0Ei6a0p0+wyMcHVKzde4VSPzICJJ/zyAyLoCoPtY/BrSEsMeNTCGEH7AUeEBKubPe84FAuZSyRghxNzBZSjnydGUlJCTIxMRE2wZsA7XVRpa9u5WCzArG3NkL70B3jLV1B+3aegfw2noH7lrLQdtYe+IAbqxb5/gBvt42Zyukszdj7uyNT5C7Dd5x61BeVMOKT3aQe6iUyF4BxAzsQHTfIKsPTKa0TFlhNcs/2EZJfhWX3taLrgNaX9I2Gkwsfj2RytJapjw3BA8f+/bOF0IkSSkTmnzNXi1ahBDPA5VSyrdP8boWKJRS+p6unNaaCMDS9X3JO1soym7evLs6vQYXVy06Fy06Vy0ueg06vRadXouLq+Wxi16LTq+pe73u8bHnXS2/uzSxjVavQevkVWp7MRpMJK04zN6NOZQVVKPRCiLjAogZGEJU32Bc3dv25TJnV5BVzvIPtmOoNnLFvfGEd/d3dEjn7NhMfhE9/Rl7b7xdhr44xiGJQAgRDBiklMVCCHfgV+ANKeWP9dbpKKXMrnt8DfCklLKpG8rHteZEAJZkcCSlAK1O08TB/cSBXOeiseuXRLG0RMk9VMb+pKPsT8qlvKgGjU4QGRdIt4QQouKD2vw9FGeTtb+Yn/+bjNZFw7gH+hEU4fg+Ai2V/Ec6f32bavfLW6dLBLb8VncE5tSd6WuAhVLKH4UQLwGJUsofgAeFEOMBI1AITLNhPE7BzcuF7oNDHR2G0gQhBB2ifegQ7cN5E2I4eqiU/Um57E/K5VByPlqdhs69A4kZGELnPoEqKdjY4V0FrJi1A+8AN8Y92BefwLZxCbPP8AgO7yzg7+/2E9bdzyozpbWU3S4NWUtrrxEorY80S3IOlliSwpZcKktq0blo6NwnkJiBHejcJ9Bpmy+2VhUlNcx/aSNe/m5c9XA/3L2ca7TblqosrWXBfzbi4ePKdU8loHWx/WVaR9UIFKVNEBpBxxg/Osb4cf513cg5UMz+xFz2b83jwJY8dHoNUfFBlppCr0CbTX7SXkgp+f2rPZhqzYy5o1ebSwIAHj56Rt7ck59mJvPPsgNcMLGbQ+NRiUBRzoJGIwjr5k9YN38umNydrNRi9iflcnBrLvsTc3Fx1R5PCpG9AtC5qKRwtnb9lcWRXQVcOLl7m+3cCJZBKo91boyMCyAyLtBhsahLQ4piBWaTmcxUS03h4NY8qisMuLhpie4bRLeBHejUM8Au1f/Wrji3km9f3kRoF1/GP9ivTYx1dTrGWhMLX91MTaWRKc8Ptmntxymaj1qLSgSKszOZzGTuLbIkhW151FQa0bvr6NI3iJiEDkT08EerU0mhMbNZsvTtLRRmV3D984Px8neeAeRsKT+jjEWvJ9K5VyCXT+9js9aC6h6BotiRVqshMi6QyLhALr4hlow9RexPPMrB7fns2ZCDq4eOLv2CiUkIITzWX/XnqLP118PkHCzhklvj2k0SAAiK8GbY1V35e/F+UtZl0etC+86qBioRKIpNHWty2rl3IMMNZtJ3Fx5vfbR7fTZuni506R9MzMAQwrv7Of24ObaSl17GpuVpdB0QQvfBrWMmPGvqO7ITR3YVsG5hKmHd/Ox+b0RdGlIUBzAaTBzZVXi8j4KhxoS7twsxA0IYcnXXdtWb2Wgwsei1RKrLDVz//BCnHE7aHiqKa1jwn014Bbgy8ckEq18+VJeGFMXJ6Fy0dOkXTJd+wRhrTRzeVcD+pFx2/ZVFSX41Y++LR9PGb5Qes+mHNAqzKhh7X3y7TQIAnn6ujLipBytm7WDjDwc5b0KM3fbdPuuhiuJEdHotXfuHMOaO3lx0fXeO7CrgnyX7HR2WXWSlFrF19RHiLgxzuhE5HaFLv2B6XRjG1lVHyNhTaLf9qkSgKE6k14Xh9BkewbbV6exen+3ocGyqttrI6tm78Qly5/xr7Xf26+zOn9gNvxAPVs/eTXW5fSZOUolAUZzMBdfFENHDnzXf7CH7QImjw7GZdYtSKS+s5pJbeqpxm+pxcdVy6e29qCqrZc28PXaZ81wlAkVxMhqthjF39sbb340Vs5IpK6x2dEhWl5acz+6/s+l/aWc6xvg5OhynExzpzZDxXTiwNc8uNUOVCBTFCbl5ujD2vnhMBjM/f5yMocY557o9F1Vltfzx9W4CI7wYPC7a0eE4rf6jIwmP9eevhakUH6206b5UIlAUJ+Uf6smld/SmIKOc32anIM2tq6l3U6SUrJm3l5oqI6NvjVM9rE9DaASXTOuJVitY9cUuTKazn4WwudRfQVGcWOfegZx3bQwHtuax+ac0R4fTYns35nBwWx5DxnchMNzx4/A7Oy9/N0ZM7UHu4TI2L7fd318lAkVxcn1HdaLHsFA2/3SI/Um5jg7nnJUVVvPXgn10jPGl3yWRjg6n1eg6IISe53Uk6ZfDZKUW2WQfKhEoipMTQjD8hh6EdvHlt9kp5B0pc3RIZ02aJb/NSUFKGHVLXLvpLGctF0zqhm+wO1mptmlFphKBorQCWhcNl0/vg5uXCz9/nExFSY2jQzoryX9kkLm3mAuusxzQlLOjd9Mx6ZlBJFwRZZPyVSJQlFbCw0fPFffGU11hYMWsHRgNraMlUWFWBf8sPUBUfBA9z+/o6HBaLVv2tVCJQFFakeBO3lwyLY6jaaWsmbfXLp2NWsJkMrN6dgoublpGTO1hs7H2lZaxWSIQQrgJITYJIbYLIXYJIV5sYh1XIcS3Qoj9QoiNQogoW8WjKG1F1wEhDB4Xzd4NOWxble7ocE4r8edD5B0pY/iNsXj4tL25h9sKW9YIaoCRUsq+QD/gMiHE0Ebr3A4USSljgHeBN2wYj6K0GQlXRBEzMIT1S/dzaEe+o8Np0tG0UpJWHCZ2aChd+4c4OhzlNGyWCKRFed2vLnVL43rsVcCcuseLgVFC1R0V5YyEEIy8pSfBnbz59fNdFGZVODqkBgy1JlbPTsHTV8+Fk7s7OhzlDGx6j0AIoRVCbANygVVSyo2NVgkH0gGklEagBAi0ZUyK0la46LVcPr0POr2Wnz5OtttIlc3xz5IDFB+tZNQtPdvVJDutlU0TgZTSJKXsB0QAg4UQvc+lHCHEXUKIRCFEYl5ennWDVJRWzDvAjSum96GiqIaV/9th02EImis9pZAdazKIHxlBRI8AR4ejNINdWg1JKYuBP4DLGr2UCXQCEELoAF+goIntP5VSJkgpE4KDg20drqK0KqFdfBkxNZbMvcWsW5jq0FiqKwz89tVu/EM9GHZ1V4fGojSfLVsNBQsh/OoeuwOjgT2NVvsBuKXu8UTgd+ns7eEUxQnFDu1I/9GR7Fybyc61GQ6L488F+6gqreWSW+PQ6bUOi0M5O7a8eNcRmCOE0GJJOAullD8KIV4CEqWUPwCfA18LIfYDhcAUWwWzZm8uL/+0GwEIAQLBsdvSQojjz2uEqHvd8sSJ9RuuJ7A8efJ2TZfbeHvq1tPU2+bkcpvennrbNN7+WLmN3+ex7Wny+abLbvDeTvo8Tt7+lGWf6TNp9HnX/xvU/0w09bdt8L5Pjktz0mchLJ9VE5+xplHMDfclmoy18Xem8Xtv/B6o/3zjz+kU76Hpv0cT38G613pf0Zm8zHL+/HYfHoFuhMX6n+JvUv9zFGf1f3Q6qYlHSd18lMHjognp7GO1chXbE63tBDwhIUEmJiae9XZJhwv5fF0aUmJZkHU/Lb9T73ezrP+a5fNpsE2j7an73Swt68vj61seyCa3P1F24/2dKLNxeSe2p95rDbdv+F4abN+csuu9n8afh+L89BJuLHPFUwrmetVQrG3eH67ZJzv11qmfTD3MMDFXS6kOfgo2111rOJF8GibGeonzFEnqVImaxjGe8kTlxHoa0fB9ND7xOjkRn5wsTz7RaHgyYdlPw/ibTvonn+Qc2+7YZ6Jpct+W7YZEBzA89tya4gohkqSUCU291m5u5w/sHMDAzurGVUvJJpJW/UQCJyeW+us1TjKNy6BR8pH19klTz58U04ny6yewY883TtYcf+7USbdxUuSk1+vv68wnFGfzHk46mWh0otHUiYq5zID51xzuFF4wMhRcNM0vn5PXq3/icPyzqv/3NpvxTSpBL2phiD9jPHUnn5Qce9+nKLfxe2p8QnKmkx3zaT6PBvs2g8R80r7M8hSfQ922TX2vT3wX6pfT8GTtRNwnf58bbGdueJJ2qu00gnNOBKfTbhKBYh3HzkzqfnNkKMppZHTrwPL3t9EptYor7om36WifO//MZG1eHhdO7k78iAib7UexHTXWkKK0QRGx/lw4uRuHdxSw4fsDNttPcW4lfy9OJaKHP30uDrfZfhTbUjUCRWmjel8cQUFmBVt/PUJAmCc9hlp35E+zWfLb7N1otBpG3dIToeYYaLVUjUBR2rALJncjPNaPP+buIeegdSc12frrYXIOlnDRlO54+btZtWzFvlQiUJQ2TKvVcNmdffDyd+PnWTsoK6y2Srl56WVsWp5G1wEhdB/cwSplKo6jEoGitHFuXi6MvSceY62JFbN2YKht2YQ2RoOJ1V+m4ObpwvAbYq3aF0FxDJUIFKUdCAjz5NLbe5GXXsZvs3cfb2Z5Ljb9kEZhVgUjb+6Jm5eLFaNUHEUlAkVpJ6L6BDHsmq4c2JJL4s+HzqmMrNQitq4+Qq8Lw+jcWw0U3FaoVkOK0o70Hx1JYWYFm5anEdDRk64Dmt85qbbayOrZu/EJcue8a2NsGKVib6pGoCjtiBCC4VNj6RDtw+rZKeSllzV723WLUikvrOaSW3radCJ1xf5UIlCUdkbnYpnQxs3ThZ//m0xlae0Zt0lLzmf339n0v7QzHWP87BClYk8qEShKO+Tp68oV98RTXW5gxawdmAynntCmqqyWP77eTWCEF4PHRdsxSsVeVCJQlHYqONKbUdPiyDlYwpr5e5tsSSSlZM28vdRUGRl9axxanTpktEXqr6oo7VjMwBASxkaxZ302239LP+n1vRtzOLgtjyHjuxAY7uWACBV7UIlAUdq5wWOj6do/mPXf7efwzhMzxZYVVvPXgn10jPGl3yWRDoxQsTWVCBSlnRMawahpcQSEe/HrZzspyqlAmiW/zUlBSrhkWpxNh7FWHE8lAkVRcHHVMvbeeLQuGn6amczmn9LI3FvMBZO64RPk7ujwFBtTiUBRFAC8A9y4/O4+lBVWs/mnQ0TFB9HzPOsOXa04J5UIFEU5rmOMH6Nu6UmHaB+G36gGlGsvbNY9UAjRCfgK6IBlys1PpZTvN1pnOLAMSKt7aomU8iVbxaQoypl1HxxK98Ghjg5DsSNb9hM3Ao9JKbcIIbyBJCHEKillSqP1/pJSXmnDOBRFUc5Z6cqVCL0e75EjHR2KzTTr0pAQ4rrmPFeflDJbSrml7nEZsBtw3KSmJiNkJzts94qitD6mkhKynn6GjIcepiq57R4/mnuP4OlmPtckIUQU0B/Y2MTLw4QQ24UQK4QQvZpb5lnbsQg+uRDm3wDZ2222G0VR2o7i75Ygq6rQ+viQ+cijmEpLHR2STZw2EQghLhdCfAiECyE+qLfMxnLp54yEEF7Ad8DDUsrGn+IWoLOUsi/wIfD9Kcq4SwiRKIRIzMvLa85uTxZ7OQx/Bg6vg08uUglBUZTTkiYTRd98g3vCQDrN/AjD0aNk//vZFk3q46zOVCPIAhKBaiCp3vIDMOZMhQshXLAkgXlSyiWNX5dSlkopy+se/wy4CCGCmljvUyllgpQyITg4+Ey7bZq7Hwx/Eh5KVglBUZQzKl+7FkNGBgFTp+Lerx8hjzxC2apVFH3zjaNDszrRnOwmhHCRUhrqHvsDnaSUp71gJiztzuYAhVLKh0+xTihwVEophRCDgcVYaginDCohIUEmJiaeMeYzqiqGjZ/APzOhpgRix1oSRce+LS9bUZRW78htt1FzMI2YVb8iXFyQZjPp99xD5fp/iPp2AW5xcY4O8awIIZKklAlNvdbcewSrhBA+QogALJdz/ieEePcM25wP3ASMFEJsq1uuEEJMF0JMr1tnIrBTCLEd+ACYcrokYFXHaggP19UQDtXVEBbcqGoIitLO1Rw4QMX6f/CfMgXhYpmXWWg0hL3+OtqAADIeeQRTebmDo7Se5twxHwwAACAASURBVNYItkop+wsh7sBSG3hBCJEspYy3fYgNWa1G0FjjGkKPK+HiJ6Gj3d+ioigOlvPSSxQv/o6YNX+gCwho8FplYiKHb5mGz5gxhL3zdqvpdGeNGoFOCNERmAT8aLXInEmDGsLTkPaXpZXRghtVs1PFLgzZ2aRPv4eKTZscHUq7Zioro/j7ZfiMHXtSEgDwSEgg+IEHKP35Z4oXLXJAhNbX3ETwEvALcEBKuVkI0QVItV1YDuTuB8OfUglBsbv8/35M+Zo1HLntdgrnzWuTrVNag5IlS5CVlfhPvfGU6wTedSee553H0VdepXrvPjtGZxvNujTkTGx2aehUqoph4yz457/qkpFiM4bsbPZfOgbfsWMxlZRQ/scf+F47gdAXXkCj1zs6vHZDms0cuOxydIGBRM0/fesgY34+B6+5Bq23D9GLFqLx9LRTlOemxZeGhBARQoilQojcuuU7IUSEdcN0UqqGoNhBwWefg5QEP/gAETM/IvCe6ZR8t4QjN92M4Wiuo8NrN8r//BPDkSME3DT1jOvqgoIIf+statPSyPnPy3aIznaae2noSyx9B8LqluV1z7Uf9RPCxU+phKBYjTEvj+JFi/C9+ipcwsIQGg0hDz1E+PvvU52ayqGJE6nats3RYbYLRXPnoQsJwXv06Gat7zl0KEH33EPJ999TvLTJ/rCtQnMTQbCU8ksppbFumQ2cY8+uVs7dD0Y8XS8h/HkiIeTscHR0SitU8MWXSKORoLvuavC8z5hLiZo/H+HmxuGbbqb4u+8cFGH7UHMwjYp16/CbMvl4k9HmCLrvXjwGDybnpZeoOXDAhhHaTnMTQYEQYqoQQlu3TAUKzrhVW9ZUQph1AXw7VSUEpdmMRUUULViAz5Vj0UeePC+wW2x3ohctxGNQAtn/fpac/7yMNBgcEGnbVzRvHsLFBf9Jk85qO6HVEvbWW2jc3cl8+BHM1dU2itB2mpsIbsPSdDQHyMbSEWyajWJqXdz9GyaEg2tVQlCarXDOHGR1NUF3333KdbR+fnT69FMCbr2VonnzOHLb7RgLC+0YZdtnKi+nZOlSfK64HF3QSaPcnJFLhxDC3niDmtRUjr7yqg0itK2zaT56i5QyWEoZgiUxvGi7sFqhBgnhyUYJYaejo1OckKm0lKK58/AeMwbXrl1Pu67Q6ejw5L8Ie/MNqpKTSZs4keqUxlN7KOeqZOn3mCsr8Z965pvEp+J14QUE3nknxYsWUfLjT1aMzvaamwjipZRFx36RUhZiGVZaaczdH0Y80yghnA/f3qQSgtJA4dy5mMvLCbpn+plXruM7fjyd580Ds+TQDTe2ugOOM5JmM0Vz5+LWNx73Pn1aVFbwgw/g3r8/Oc8/T+2hQ9YJ0A6amwg0dYPNAVA35pAtZzdr/U5KCGtOJATVyqjdM5VXUDTnK7xGjsQtNvastnXv3YvoxYtw69WLrMcfJ/ftt5Emk40ibfsq/v6b2sOHCZh6U4vLEi4uhM94B+HiQsajj2KuqbFChLbX3ETwDvCPEOI/Qoj/AOuBN20XVhvSVEL45EL430hI/BKq2+ZEF8rpFS+Yj6mk5KxqA/XpgoLo/OUX+F0/hYLPPif97umYSkqsHGX7UDh3LtrgIHzGXGqV8lw6dqTja69Rk7Kb3DffskqZttasRCCl/AqYABytWyZIKb+2ZWBtTv2EMOZVqK2EHx+Gd2Jh6T1w6G9oZb28lXNjrqqi4MvZeF5wQYsuRQi9no4vvEDoSy9SsXEjaZMmUZPaNkd+sZXaQ4eoWPsn/pMmI6zYg9t75AgCpk2jaN48Sn/51Wrl2kpzawRIKVOklB/VLeou1bly94dh98G9/8Adv0H8JNi9HGZfAR8OhL9mQFmOo6NUbKh40SJMBQXnXBtozH/SJDrPmY25opJDk6dQtnq1VcptDwq/+QZcXPCbfHZNRpsj5NFHcOvTh+xnn6U2I8Pq5VtTsxOBYmVCQEQCjHsfHt8LV38MXh3gtxdhRhx8MwX2/AQm1Wa8LTHX1FDw2ed4DB6Mx8CBVivXY8AAor9bjD4mhoz7HyDvw4+QZrPVym+LTOUVlCxZis+YMbiEhFi9fKHXE/7uDAAyH30MWVtr9X1Yi0oEzkDvCf1ugNtWwP1JcP6DkLUFFtxgSQq/Pgd5rX+EQwVKli7FmJtrtdpAfS4dOtD566/wveYa8mfOJOOBB9vU5CnWVrLse8zl5QScZpTRltJHRNDx5ZepTk4md8aZ5vJyHDX6qLMyGWH/KtjyNexbCdIEnYbCgJsg7mpw9XJ0hMpZkgYDB8Zchi4khM7zv7HZhCZSSoq+nsvRN95AHxVFp5kfoY+Kssm+WispJQfHXonG05Oohd/afHKZnJf+Q9E33xDx3//iPXKETfd1KtaYmEaxN60OYi+H67+BR3fD6JegsgCW3We5wbzsfkjfpG4wtyIlPyzHkJVF0D3TbXrgEUIQcPNNRH7+OaaCAtKum0T5X3/ZbH+tUcX69dQePEjA1BvtMsNYyJP/wjWuJ9lPP40hO9vm+ztbqkbQmkgJ6RsttYRdS8FQAUGxllpC/BTwap/jALYG0mjkwNixaD29iPpusd2mN6zNyCTj/vup2buX4EcfIfCOO1rN1Iq2lH7PvVQlJxPzx+92m++h9tAh0iZci2tsLJ2/mnNWA9tZg6oRtBVCQORQuHqm5Qbz+A/BzRd+fRZm9LCMgLrvF8tlJcWplK5YieHwEQJtXBtoTB8RTtQ38/C5/DLy3plB1mOPY66qstv+nVFtejrla9bgP3mSXSf90UdFEfqfl6jaupW8Dz+y236bo131Ds6tzCXEw/qtAxzC1RsG3GxZcvfA1q9h+wLY8yN4d7TcfO4/FQK6ODrSdk+azeR/MgvXbt3wHjXK7vvXeHgQ9s47uPbsSd6Md6lJSyPiww/RR4TbPRZnUDTvG9Bq8Zs8xe779h07lsoNGyn49FM8Bg3C68IL7B5DU2xWIxBCdBJC/CGESBFC7BJCPNTEOkII8YEQYr8QIlkIMcBW8fxy6BfGLhnLktQlbW8u2JAeMOYVy72EyXMhNB7WvQsf9Icvx1oSRG2lo6Nst8pWraZ2/wECp9+N0DimEi6EIOjOO+n0ySwMGRkcuu46KjZuckgsjmSuqKD4u+/wuXQ0Lh0cc1LY4Zmnce3Wjawnn3Sa2eds+a00Ao9JKeOAocB9Qoi4RutcDnSrW+4CPrZVMAM7DKRfSD9eWP8CT697mkpDGzww6vTQcxzcuBAe2QUjn4PSTFh6t+UG84+PQOYWdYPZjqSU5M+ahT4qCp/LLnN0OHhddBFRC79FGxDAkdtuo/DruW3vxOg0SpYvx1xWhr8VxhU6Vxp3d8LfexdzVRVZTzzhFONE2SwRSCmzpZRb6h6XAbuBxnXRq4CvpMUGwE8I0dEW8QS5BzHrklnc1+8+VqStYPKPk9lbuNcWu3IOPmFw0ePw4FaY9hPEXgHb5sP/RliGx97wMVS077mF7KF8zRpqdu8m8O67EVqto8MBwDU6mqhvF+B18cUcfeUVsv/9bKsZHK0lpJQUzZuHW1wc7v37OTQW165dCX3+eSo3bSL/vzY7/202u9RThRBRWIat3tjopXAgvd7vGZycLBBC3CWESBRCJObl5Z1zHFqNlul9p/PZpZ9RYajgxp9vZPG+xW37jEgIiLoAJnxiucE8dgZoXWDlU/B2N/jqakiarZKCDUgpyf94Fi4REfheOdbR4TSg9fIi4qMPCbr3XkqWLOHwzTc7zWUKW6ncuJGa1P34T53qFC2n/K65Gt+rryb/v/+lYsMGh8Zi80QghPACvgMellKe01CbUspPpZQJUsqE4OCWN5EcFDqIReMWMSBkAC/+8yJP/fUUFYaKFpfr9Nx8YdDtcNcamP43nP8QFB+G5Q9ZksKc8ZD4BZSfe7JVTqhYv57q5GQC77zT7k0Fm0NoNAQ/+ADhH7xPTep+0iZeS+XWrY4Oy2YKv56L1t8fn7FXODqU40KfexZ9dDSZTzyBMT/fYXHYNBEIIVywJIF5UsolTaySCXSq93tE3XM2F+geyKzRs3iw/4OsPLSSKT9OaduXihoL7Q2XvAAPbIHp6+CCRyz3E358BN7pDrOvhM2fQXnbPku0pfyPP0YXGorvNVc7OpTT8rn0UqIWzEfj5s6Rm2+hePFiR4dkdbUZmZT/8Qd+kyahcXV1dDjHaTw9CX/3XcylZWT960mHjQ9lsw5lwlL3mgMUSikfPsU6Y4H7gSuAIcAHUsrBpyu3qQ5lBoOBjIwMqs9x0ugaUw3F1cWYpRkfVx88XTzPqRxHcXNzIyIiApeWnnVKCbkpsOt7SPke8vcBAjqfD72uttyI9g61SsxtXeXmzRy+6WY6/PvfBNx07tMf2pOpuJjMxx6n4u+/8b/hBjo8+2+HtXKytqNvvUXh7DnE/LYal1Dn+w4XLVxIzvMvEPzwwwRNP/X81S1xug5ltkwEFwB/ATuAY2nuGSASQEo5qy5ZfARcBlQCt0opT9ttuKlEkJaWhre3N4GBged87c9oNpJZnkl5bTk+rj6EeYah1TjHzb3TkVJSUFBAWVkZ0dHR1iwY8vacSAp5ewABkcNOJAWfMOvtr405ctvtVO/bR8zqVWjc3BwdTrNJk4nct96mcPZsgh99lKC77nR0SC1mrqoidfgIPIcNI+I95xz4TUpJ1mOPU7pyJZ2/moNHQpPH6xY5XSKwWYcyKeU64LRHZWnJQve1dF/V1dVERUW16AaQTqMj0juS/Kp8citzqTZWE+EdgbvOvaXh2ZQQgsDAQFpyE/0UBUNIT8sy4mlLp7WUZZaksOJflqXT0LqkMB5822fnpKZUbd9Oxfr1hDzxRKtKAgBCqyXkyX9hzD1K3nvv4R4fj+fQIY4Oq0VKli/HXFJi01FGW0oIQehLL1K1ayeZjz1O9PdL0fn7n3lDK2kb9T6wSisAIQTBHsFE+UZhlmbSStIorCp0+lZFdmkBEdIDhj9pmVDnvs0w4lmoLbe0Pno3Dj4bDf/MhOL0M5fVxuV/PAutnx/+UyY7OpRzYjko/Qd9VBSZjz3WqlsTSSkpmjsP1x49cLfi/A+2oPXyInzGDEyFhWQ/9bRd7xe0mURgTZ4unnT164qniyfZFdlklGdgMju+04fTCO4OFz8B9/xtmT9h5HNgrIJfnoH3esP/RsH6D6HosKMjtbvqlBTK16whYNotaDxb172m+rRenkS8/x7mykoyH3sUaWidEyRVbtpMzb59BNzkHE1Gz8S9Vy9CnnyS8rVrKZw9x277VYngFI5dKurg2YHSmlIOlhykynj6wbpWrlxJbGwsMTExvP766ye9XlNTw+TJk4mJiWHIkCEcOnTo+GuvvfYaMTExxMbG8ssvvxx//rbbbiMkJITevXtb7b1ZVVCMpePa9HWWFkijXgCzwTIQ3vvx8OkI+Pt9KDp0fBPD0aOULFtG1jP/Zv/oS8l5+RWnr3U1V/6sT9B4e+N/o/Nehmgu127d6PjSi1QlJpH73nuODuecFM2di9bPD5+xztWP43T8b7wB79GjyZ0xg6pt2+yzUyllq1oGDhwoG0tJSTnpOWuqqK2Qewr2yF35u2R+Zb40m80nrWM0GmWXLl3kgQMHZE1NjYyPj5e7du1qsM7MmTPl3XffLaWUcv78+XLSpElSSil37dol4+PjZXV1tTx48KDs0qWLNBqNUkop165dK5OSkmSvXr1OG6OtP4OzVnBQyr/elfKTi6XhST9ZcmuIzLquv9x/0RCZEttDpsT2kHsHD5Fpk6fIlNgeMveDDx0dcYtV79tneS/vv+/oUKwq6//+T6bE9pClq1Y5OpSzUpuZKVN6xsmjb7/t6FDOmrGkRKaOHCVTR4yUxuJiq5QJJMpTHFfb3OijLy7fRUrWOfVbO6W4MB/+PTaWzPJMcipyqDRWntSqaNOmTcTExNCli2W0zylTprBs2TLi4k4Mr7Rs2TL+7//+D4CJEydy//33I6Vk2bJlTJkyBVdXV6Kjo4mJiWHTpk0MGzaMiy66qEHNoTUwlZZSuS2Nyo1VVGzwo2avpbmeRl+NR1ARfv1q8IzrjOvF10Kvq8l+90vyZ85EFxzcaq+rA+R/8ikaDw/8b3LcODa20OHpp6nesZOsp54mekl39JGRjg6pWYrmzwfA//rrHRzJ2dP6+BD+7gwO3XAj2c8+S/gHH9j00pa6NNRM9S8VldWUcaDkAFWGE5eKMjMz6dTpRN+4iIgIMjMb9o2rv45Op8PX15eCgoJmbevMzJWVlK/7m9x33iHtuknsGzqMjHvvo2jBt+gCAwh+5BGivl1A9y3JdFqylsAHn8EtzBPxx38QHw2kY4df8YrrQM5LL1K28idHv51zUnvoEKU//4z/DdfbtbWHPWj0esLfew+0WjIefAjzOfbXsSdzdTXFCxfhPWoULmGts5mze3w8IY89Rtmq1RTNnWfTfbW5GsEL43rZrGwhBEHuQXjoPMgoyyCtNI0OHh0IcAuw2T6dkbm2lqpt26jcuImKjRuo2p4MBgPodLj37UvQ9Ol4DB2Ce79+J0/84RcJ591vWUoyYPdyROqvhMev53COF5mPPUZk0vt4DL8Suo6EDr0sTVmdXP6n/0Po9QRMm+boUGxCHxFO2BuvkzH9HnJefpmwl192dEinVfrTT5hKSvCf2jo6851KwLRbqNy4kdw338S9f3/ce9vm+NbmEoE9eLh40MWvC1nlWZZLRYZKQjuGkp5+oulkRkYG4eEN29aHh4eTnp5OREQERqORkpISAgMDjz9/um0dSRqNVO/aRcWGjVRu3EDllq3I6mrQaHDr1YvAabfgMXgIHgMHoPHwaH7BvhEw9B4Yeg8aQxWdxv3K4UdeJn1hBlH5L+Lq+xx4hVoSQteR0HUEeAbZ7o2eo9qMTEp++MFSGwhyvvisxXv4cAKn303BrE/w6D8Av2snODqkJkkpKfx6Lq7du+MxeJCjw2kRIQQdX3uVtGsmkPnoo0Qv+Q6tl5fV99NuEoG5uhpTURHC1RXh6orG1RWhO/e3r9Po6OTdiYLqAnIrcgnoHsC+1H2kpaURHh7OggUL+OabbxpsM378eObMmcOwYcNYvHgxI0eORAjB+PHjueGGG3j00UfJysoiNTWVwYNPO9KGTUmzmZq9e+sO/Bup3LwZc4VlUD7X7t3xm3QdnkOH4pGQgNbHxzo7dXFHN/AqOn0zkEPXX8+RLcFEPTcZl+JE2LcStn8DCOjY15IUYkZBxGDLHAwOVvDZ/ywd+26/3dGh2FzwAw9QtW07OS+9hFuvONx69HB0SCepSkqiZs8eQl96sVU0GT0Tnb8/4TPe4fBNN5P7zjt0fOEF6+/D6iU6KVlTg7GoCOp10hBabcPEcGxxcWnWF6jxpaInX32SSy69BMyWZp+9evXi+eefJyEhgfHjx3P77bdz0003ERMTQ0BAAAsWLACgV69eTJo0ibi4OHQ6HTNnzkRbN3b99ddfz5o1a8jPzyciIoIXX3yR2618wJFSUpuWRsWGDVRu2Ejlpk2YiosByzyrPldeiefQIXgMHowuMNCq+25MHxFB5KefcnjqTaS/v5LO8+ai9fKE7G1w4HfY/zus/wDWzQC9F0RdaEkKXUdapuW08z++4ehRSr5bgu+1E3Dp0MGu+3YEodUS/s7bpF0zgYyHHiJ68WK03t6ODquBwrnz0Pj64jtunKNDsRqPAQMIf+dtPAbZpoZjs7GGbKWpsYZ2795Nz549z7itlBJpMCBrapA1NZjrfsqamoazBGk0aPT6k5OEXn/KQbiMZiNZ5VmU1ZbhrfcmzCsMncZ+ebbZn0FtLcbCQoz5BdTs3WM569+wAWPdEBW6jh3xHDrUcuAfMsRhA3RVbNjAkTvvwqNvXzp9/lnDESOrS+HQX7D/Nzjw24k+Cn6dTySF6Issw27bWM6rr1I07xu6/vJLu5oDuDIpicM334L3yBE2b9FyNgw5OewfdQkB026hwxNPODocp+KQsYackRACodeDXg+NzmKk0dggMZhrajBXViJLSuqXgNDr0bi5IvSuCDdXNHpXhKsendZyqaiwupCjlUc5WHyQCO8IPFzO4pr5OZJmM9JkomrXLkwFBRjz8jEWFGAqyD/+2FiQjykvH1OD9wPawEA8hwzBY+gQPIcOxaVTJ6f4p/YcOpSw118j67HHyXriX4S/O+PEDF9uPtBjrGUBKDxYlxR+h+SFljkVhBY6Da67tzAKwvqBlQcRNObnU/ztQnzHj29XSQDAY+BAQh5/nNw33qDwy9kE3naro0MCoGj+ApAS/+tvcHQorUq7SgSnI3Q6tDodNBoWQJpMyNrak5KELCtrMPevcHFBuLri4+qKhy6AXFMJR4rSCPLuQKDb2Y+KKqVEGo1gNCLrLTT12GTCePQoh+67v0EZGg8PtMFB6AKDcI3ugm7wYLSBgegCg9AFB6GPjEQfE+MUB/6m+I4diyk/n6Ovvc7RV16lw3PPNh1rQBcY3AUG3wnGWsjYbKkp7P8N/ngV/ngF3P2hy3BLUug60iqD5BXOno00GAhsAyN0nouAabdQtWULue+8g3vfeDwcPJaPuaaG4oUL8Roxot0l5pZSieAMhFaLcHdH495wFFJpNh+/zGSurkHW1iCrazBWWu5DhNStZ87LoUyfh6u7N1o3N8slJp2uiQO7CWk01P1uQpqMTQek0SB0Osvi6orw9LQksepqIj760HKgDw5GFxh4UsytUcAtt2A4mkvhF1+gCwk581jtOj1EnW9ZRj0PFflwcM2JGsOupZb1gntYkkLMSMt8Cy5n91kZi4oo/GY+Ppdfjqs1h/9uRYQQdHz1FaonTiTz4UeIXrrEoa2mSn9egamoqNXM/+BMVCI4R0KjQbi6gqsr2noNZxrfh6iqLMVUXYmxtBhz8SkKO3Zw1x47uNc91mktUxxqdQgXnSUpnWICdE1BAd42GMPcGYQ8/hjGvDzy3nsPXUgIfhOuaf7GnkHQZ6JlOTbxzrF7C5s/gw0zQesKnc+zJISIBAgfaLn8dBpFX3+NrKy02SQirYXW25uI99/n0OQpZD72OJFffH7K76gtSSkp+vprXLvF4DGkdQ+b7QgqEVhZ4/sQ3gRRZagivTwds8FAB50/3lrPE2f1Op1D/nFaE6HREPbKy5gKCsh+7jl0gQF4XXzxORQkLB3UOvSC8x+E2ko4vN5SUzjwO/xxrJOUgJA4S1LoNBgiBkFgN6hrKGAqK6Pw67l4jx6Na7du1nujrZRbjx6EvvAC2c88Q94HHxLySJMTEtpU1dZtVKekEPp/LzjtpU5nphKBHbi7uNPVtytZFVlk1RThpTMQ4hqCu8555k51dkKvJ/yDDzhy881kPPwInWd/iXvfvi0rVO8B3S6xLABVxZCZZLnHkLHZMgnPlrqhgN18IdySGIr+LsBcVkbQPdNbtv82xG/CNVRuSaLgk09w798P7+HD7br/orlz0Xh7t6kmo/akxhqyotMNQ63VaFn46UImXDiBS4ddyoiRI/h7599UGCocFG3ro/XypNOnn6ALCiL97unUpKVZdwfufpbmp8Ofgqnfwb8OWSbhuWomxF0NZTmYV71B4bfL8Aqrxu2PW2HZfZA0B46mNOij0h6FPvssrj17kvXkU9Rm2G+sLMPRXEp//RW/a69t1XNAOJJKBFZiMpm47777WLFiBSkpKcyfP5+UlJQG6wwYMICtSVtJ2ZHChGsn8PJzL3Oo5BBpJWmU1Za1mTH5bUkXFETk/z4FjYb0O+483v/BJjQayyQ8/afC+A/g3vUURb6CqVZL0E0TLf0W9vwMyx+Ej4fBG53hq6vg91cgdRVUFtouNiekcXMj4v33wGwm86GHMNfW2mW/xd8uAJMJ/xtVk9Fz1fYuDa14CnJ2WLfM0D5w+ckTzdTXnGGoR4wYcfzx6ItGs2zhMkI9Q8mvyudI6RHcdG4EuwfjrfdW1zlPQx8VRadPZnH4lmkcuetuOn/9lU3GX2nMXF1Nwdfz8TxvGO63vmV5UkpLP4b0TZCxyXJJ6a+3QdbVDgK7We4xdBpk+RkSZ/X+DM5EHxlJ2OuvkXHf/Rx99VU61g27bivm2lqKvl2I18UXo683gq9ydmyWCIQQXwBXArlSypOm1xJCDAeWAcfq90uklC/ZKh5ba2oo6Y0bN55y/c8//5zLL7+cQPdA/N38KakpIb8qn/SydPRaPcHuwfi4+qARqtLWFPc+fYh4/z3S77mXjAceIPKTTyw36W2oeNFiTPn5BL0748STQkBgV8vSr27c+5pyyNpalxgSIfXXurGSsAyLEdb/xE3oiEFOOZBeS3iPGkXA7bdR+PkXeAwYgO/48TbbV9mKFZgKCvBXTUZbxJY1gtnAR8BXp1nnLynllVbd6xnO3J3B3LlzSUxMZO3atQBohAZ/N3/8XP0orS0lryqPzPJMcqtyCXILws/NTyWEJnhdeCEdX/4P2U89TdbTzxD21punHAKkpcy1tRR8/jnuCQPPPN6LqxdEX2hZwFJrKDpkqS2k19Ua1r0Hsm5Yk4AuJ5LCsVqDEwym1xIhjzxC9fZksl/4P9x69rRZ66rCufPQd+mC53nn2aT89sJmiUBK+acQIspW5Tub5g4lvXr1al555RXWrl2Lq2vDVkNCCHxdffHR+1BuKCevKo/simzyqvIsNQdX/wazoingd/XVlj4G78xAFxxMh6eetMl+SpZ+jzEnh46vnMM4/EJAQLRliZ9kea620jKQ3rHEcHANJH9reU3jYunw1jHeclkyNB5Ce9tl7CRrETodYTPeIW3CtWQ8+BBRixZZBg+0oqrt26nesePUPc6VZnP0PYJhQojtQBbwuJRyV1MrCSHuAu4CiHTSafIGDRpEamrqaYeh3rp1K3fffTcrV64kJCTkFCVZEoK33hsvFy8qDZXkVeVxtOIo+ZX5BLgH9HbQlgAAG5BJREFUEOAWYNcB7Zxd4B13YMzNo3D2bHQhIVYf90YaDBR8+ilu8fHWO/PUe9R1YqsrT0ooSbckhZwdliV1FWyrNzOVX+e65HBs6QM+YU47cY9LSAjh77zDkVtvJfu5ZwmfMcOqB+zCr+ei8fLC96qrrVZme+XIo8kWoLOUslwIcQXwPdBk/VFK+SnwKVhGH7VfiM2n0+n46KOPGDNmDCaTqclhqJ944gnKy8u57rrrAEtS++GHH05ZphACT70nnnpPKg2V5Fflk1eZR0FVAf5u/gS6BeKidbHXW3RaQgg6PP0Uxvw8ct98E11wkFXbk5f8+BOGzEw6/PvftjvzFMIye5tfJPS+9sTzZUchJ9myZCdbEsTu5Sde9wisqzX0gdC+lp+BMaB1jhMFzyGDCX74YfJmzKBowECrDf9gzMuj9Jdf8L9+itVrGu2RTYehrrs09GNTN4ubWPcQkCClzD/dei0ZhrotqDZWk1+VT0lNCUII/Fz9CHIP4sC+A+3mMzgVc20t6XfcSeXWrXSa9TFe55/f4jKlycTBsVci3NyIXrrEOS5B1JTB0V2WpJC93fIzNwVMdc01dW6W3tPHLyvFQ4c40DvmgCnNZjLuu5/ydeuI+vor3Pv1a3GZeR/NJP+jj+i6cgX6qKiWB9kOnG4YaoclAiFEKHBUSimFEIOBxVhqCKcNqL0ngmNqTbXkV+VTXFOMlJLS9FI6RHegi18XR4fmUKayMg5PvQlDejqRX3+Fe6+WzfFa8tNPZD32OOHvvYfPZWOsFKUNmAyQv68uOSSfqEVU1w07LjSWmsLx5FD30yvYPuGVlJB27USk0WgZnM7f/5zLkrW1pI4ahVtcHJGffGLFKNs2hyQCIcR8YDgQBBwFXgBcAKSUs4QQ9wP3AEagCnhUSrn+TOWqRNCQwWSgoLqAlN0pPLzrYUZFjuKO+DvoFWibSa5bA8P/t3fn8VGV9x7HP7/MTGay7xskkAQIu1gr7lKrtlWKplQroL5qq6BypWrrUtSi9d5bb1vb2ttarXDr9bohtmjJRYqgiEsX4VoWERCBLGwhKyGEJGR57h/nZDIDyJrMJHN+79drXjPnzJmZZ87rJN95nuec59lbRdm0qZjWQ+TPf5noU+xXMp2dlBZ/A9PZSeH/lvTaGUm9pqvfwR8OH1vh0NB9UgMJOYeFw1hIKfCPq9STmj/5hPJp1xM7fjx5c5855TG2Gv53Mbvvu4+8eXOJv/jiHi5l5ApbjaA3aBAc3ScbP2FF6wrmb5pPY1sjFw64kBlnzOCLWeEdIz5cWrdvp3za9UQlJ5H/8sunNMXm/uXL2fW9Oxnw+M8jawybg3XdHdJd4VD9affprNEJ1llKgQGRORJ6YGys+gWvUvnII6TPmkXGrDtO6T3KpkylY98+Cv+ypP+FcxhpEDhA1z5oPNTIgk8X8MLGF6hrqeOszLOYccYMLhxwYd9o3w6hg2vWUPHdm/EOG8bg5/77pMahMcZQds21dDQdYMgbbyDuvtH52mvaWqx+hsBwqNwAXWNhRbmtU1oDaw7ZY63xmU6CMYY9sx+goaSEvLlzib/4opN6ffPHH1P2revIeughnXfgJGkQOMDh+6C5vZnXPnuN5z55jsqmSkamjmT62OlcPvhyR12c1rjiHXbOmkXchReS99TvrPkdTsCBd99lx223k/OTfyf5mmuO/4JI1NlpDZ/R1d/QFRIH9nZvkzyou0O667qHxIHHPKW1s7mZsilTaa+qouD11/Dk5JxwkXb/8Ic0Ln+Loe+9G5JhRSKJBoEDfN4+aOtoY/H2xfxhwx8o319OQVIBt4y5hYmFE/FEOePU0/o//pHKOQ+TVFxMzk//47g1I2MM5VOn0VZdxdA33zzh8HCMxr0BtQY7IGq3Afb/kpjU7hpDTtcprcOCTmltLS2l7NpvET10CPkvvHBCw4O019ay9ZIvk3zddWTP+VEvfbnIpZPXh8jSpUu566676OjoYPr06cyePTvo+eeee4777rvPf8XxrFmzmD59eq+WyePyMHnYZK4ecjXLy5cz7+N5/OivP+KptU9x46gbmVQ4iRTfqZ/B0R+kfOtbtFdVUfPbJ3FnZpJ5zw+Ouf3Bf/yD5nXryH7kYQ2Bo0nIsm5d8ziANb7S3k+Cw2HVPOhotZ53+6yhM7LHQs4ZeLPPIOfROey6dzZ7H/8F2Q89eNyP3ffqq5i2NlJuuKGXvphzaRD0kK5hqJcvX05ubi7jx4/n6quvDhp9FGDKlCk8+eSTIS+fK8rFFQVX8LX8r/H+rveZt34eP1/9c3710a+YMHACxUOLuTj34oitJaT/y7/QXlVN7bx5uDMzj9m+XPP073FnZpL0zW+GsIT9nDceBp1r3bp0tEHNZ8G1h42L/JP9JCI0j8uj7oUXiI3ZTeLV37AuijvKKa2mrY36+a8Qd9FFeAudOUd0b4q4IPjZqp+xuW5zj77niNQR/PCcY49hcyLDUPcFIsKE3AlMyJ3AlvotlGwtYfH2xazYsYJUXyoTCyZSPLSYEakjwl3UHiUiZD88h/baGvY+9hjujHQSr7jiiO0OfvQRB1etIuuB2UR5dQa50+LyWBeyZY2CcVOsdcZAw05/OGQOW09z5Rr2PLsc7875eBPbIT67u78hazSkD6dx9Tbaq6rI/tdHw/udIlTEBUG4nOgw1AsXLuS9996jqKiIJ554Iug1oVaUUsS94+/l7i/ezd92/40/b/0zCz5dwIubXqQopYjiIcV8vfDrpMWc/KmXfZG4XAz8xS+ouPkWdt93P66UVOLOPSdom5qnf48rNZXk664LUykjnAgk51m3ERMRYOBllZR+YzK7Pskl/4GriKrfbAXFthXQ2Q5A3VvpeBKjid/5O1j2FqQXQfpwa+KgmMhu2gyFiAuC4/1yD6errrqKadOm4fV6eeaZZ7jppptYsWJFuIuFO8rtryU0tDbwl9K/sGjrIh7/v8d54qMnuGjgRRQPLeZLuV/q92MbRfl85D31O8puuJGdd9zB4JdexDd8OADN69fT9MEHZNzzA6JiYsJcUufwZGcz8Fe/pOKW6ex5YzcDfv601aHf1gK1n9G8aiXNrzxF1pWDkMbdUPpud98DQFxGdyik27eM4cc9e0l1i7ggCJcTGYY6LeCipunTp3P//feHrHwnKsmbxNQRU5k6Yirb9m1j0bZFLN62mJU7V5LsTebKgispHlrMqNRR/fa6BFdyMoPmzaVs2vXsmHEr+fNfxjNwIDW/f4aopCRSpumUh6EWd8EFpH9vFjW/+S2xXzyLlKlTweOD7LHU/30+EhtL0r/+CRISoLMD9pVb/Q/Vn0LNp9bjDa9By77uN/XEQfowKxTSh9lhMdy6crqfz/fQ0zQIesiJDEO9Z88ecuxzpktKSvr8Ka9Dkofwgy/+gDu/cCd/3/13SraVsHDLQuZvns/Q5KH+pqOM2NCMV9OTPAMGkDdvLuU33EjFjFvJfngOB1asIP17s3Q0yzBJv/12mteuZe9PHsM3egwxY8fQXlfH/jfeIPnaa3AlJFgbRrmsyXxSC6EoYPwnY6Cp2hpzqfpT675mC5T9tXuuB7AujkspsGsOdhNTepEVFr7E0H7pPkKvI+hBS5Ys4e677/YPQ/3QQw8FDUP9wAMPUFJSgtvtJjU1laeffpoRI3qmUzZU+6ChtYE3y95k0bZFrK9ej0tcXDDgAoqHFnNJ3iV4Xf2rg/Xg6tVU3DId09FBlM/H0BVv40rqPxPARJr2+npKr7kGQSh4bSH1ryyg+te/pvCNxXiHDDn1N249ALWfQfUWuwaxxXpct83fDwFAwoCAWkRAM1N8Vr9vZtILyhwgHPugtKGUkm0llGwroepgFQnRCdZZR0OKGZM+pt80He1ftoxdd91N+szbybjzznAXx/Ga16+n7IYbibvgfFo/3YK3sIBBzz7bOx/W0WZNIxrYxFRt3x9q7N4uOt6eL2IwpAw+8nE/mD1Og8ABwrkPOjo7+HDPhyzatoi3K96mtaOVgqQCiocUM6lwEllxWWEp18loq6zEnZmpg5j1EXUvvcTef7OmBc196ikSLv1yaAtgDDTu6W5iqiu1+iXqy637QweCt/cl26FgB0NKfndQJOVZM9KFmQaBA/SVfdB4qJFlZctYtG0Ra6rWECVRnJ9zPsVDi/ly3pfxuX3hLqLqB4wxVD78CC2bN5P/yvxTHrK6VxgDzfVWTWJfOeyr6A6IfRXWrb0l+DVxmYcFRcDjpLyQdF5rEDhAX9wH5fvL/U1HlU2VJHgS+FrB1ygeUsy4jHH9pulIhY8xpv8dJ52d0FRlh0MF7CsLDoqGncH9EhJl9U0c0eRkLycOsDrIT5MGgQP05X3QaTpZVbmKkq0lLC9fTktHC4MTB1M8pJirhlxFdlx2uIuoVOh0tEPj7oCgKA8Oiv278Q/gBxDlgaRcKxTGTYMzp53Sx+qgcyqsoiSK83LO47yc83jw3AdZXr6cRdsW8Zs1v+G3a37LqLRRjMsYZ90yxzEgbkD/+xWo1Ilyue1f/p8zc157q1VrqC87LCgquqce7WEaBCqk4qPjmTxsMpOHTWZH4w4Wb1/M6srVvL71dV7ebF13kR6T3h0MGeMYlTZK+xaUc7i9kDbEuoXqI0P2SQ6Qn59PQkICLpcLt9vN4U1YKlheQh4zx81k5riZtHe281n9Z6yrXse66nWsrVrL2xVvA9YQGCNSRjAuszsccuJytNagVA/RIOhh77zzDunp6eEuRr/jjnIzMm0kI9NGMnXEVABqm2v9wbCueh0LtyzkpU0vAZARk+EPhTMzz2Rk2sh+dzGbUn1FrwWBiDwLTAKqjDFjjvK8AP8JTAQOAt8xxvzzdD+38rHHaN3Us8NQe0eOIPvB40+coXpWWkwalw66lEsHXQpAW2cbW+q3sK6qOxzeqngLsIJkVOoozsg4g3GZ4zgz40zthFbqBPVmjeA54Eng+c95/kpgmH07F3javu+3RISvfvWriAi33XYbt956a7iLFFE8UR5Gp41mdNporh9pDQxX01zTXWuoWscft/yRFze9CEBmbOYRfQ3RLh1sTKnD9VoQGGPeE5H8Y2xSDDxvrPNX/yEiySKSY4zZczqfG85f7h988AEDBw6kqqqKr3zlK4wYMYIJEyaErTxOkB6TzmWDLuOyQZcBdq2hbgtrq9f6aw7Ly5cDVpCMTBsZFA5aa1AqvH0EA4EdAcs77XVHBIGI3ArcCjBo0OecctUHdA07nZmZyeTJk1m1apUGQYh5ojyMTh/N6PTR3DDSmtu2+mB1UF/Dgs0LeGHjCwBkxWb5Q6EotYj8xHyyYrO0I1o5Sr/oLDbGzAXmgnVBWZiLc1RNTU10dnaSkJBAU1MTy5Yt4+GHHw53sRSQEZvB5YMv5/LB1mTrbR1tbK7bHBQOy8qX+bePcceQn5hPflI+BYkF1n1SAYMTBxPj1glrVOQJZxDsAgLnacy11/VLe/fuZfLkyQC0t7dz/fXXc8VR5sRV4edxeRibMZaxGWO5EWsS++qD1Wxv2E5ZQxml+0spayhjffV6lpYuxQRc5Zkdl+0Ph66wKEwqJDM2kyjRAetU/xTOICgBZonIK1idxA2n2z8QToWFhaxbty7cxVCnKCM2g4zYDM7NCT5foaW9hfL95ZTtL6O0oZSy/WWUNZSxaOsiDrYf9G8X445hcOLgoJDoqkXEesI/8qRSx9Kbp4/OBy4B0kVkJ/AI4AEwxvweWIJ16uhWrNNHv9tbZVHqVPncPoanDmd46vCg9cYYqpurKWso84dE6f5S1tesZ2lZcC0iKzaLgqSCoOamgqQCsuKytBah+oTePGvomCMj2WcL3dFbn69UbxIRMmMzyYzN5Jycc4Kea2lvoaKxIigkyhrKWLx9MQfausex97l8Vi0iKbipqSCxQGsRKqT6RWexUv2Jz+2jKKWIopSioPXGGGqaa7prEHZT04aaDSwrX0an6fRvmxmbGdRR3dXUlB2XrbUI1eM0CJQKERHx90WMzx4f9FxrRysV+yv8fRBdIbFk+xIa27qnTPS5fAxKHHREU1N+Uj5xnrhQfyUVITQIlOoDvC4vw1KGMSxlWNB6Ywy1LbVBHdWlDaVsrN3I8vLlwbWImMygGkTX45y4HK1FqGPSIFCqDxMR0mPSSY9JP6IWcajjUHctIqAvYknpEhoDJl73urxWLeKwM5ryE/OJj44P9VdSfZAGQQ+5+eabWbx4MZmZmWzYsAGAH//4x8ybN4+MjAwAHnvsMSZOnBjOYqoIEu2KZmjKUIamDA1ab4yhrqUuuBaxv5TNdZt5q+KtoFpERkxGUPNSV0jkxOXg6oHpEVX/oEHQQ77zne8wa9Ysvv3tbwet//73v8+9994bplIpJxIR0mLSSItJ4+zs4JkJ2zra2NG4w3+6a1dILC1byv5D+/3bucRFrCeWeE88cZ444jxxQY/jPHHER8cT544jLjruiO26Xhvvicfj8oR6F6iTFHFB8P6rW6jZceD4G56E9Lx4Lr6u6JjbTJgwgbKysh79XKV6msfloTC5kMLkwqD1xhjqW+v9fRC7Duyiqa2JA20HaGproqmtif2H9rO7abd/uamt6cQ+M8pz3BAJDI7AAEr0JpLmSyMxOlHHf+pFERcEfc2TTz7J888/z9lnn80vf/lLUlJSwl0kpY4gIqT6Ukn1pXJW1lkn9JpO00lzezMHDnWHRWBwBD4+fLn6YDXl7eX+17Z0tBzzszxRHn9fSZrPqu34l7se+6zHeg3GyYu4IDjeL/dQmjlzJnPmzEFEmDNnDvfccw/PPvtsuIulVI+Ikij/L/zT1d7ZHhQaXcHR0NpAbXMtNS011DbXUttcy56mPXxc8zH1rfVB/R1dYtwx/pBIj0kn1ZcatJzmS/MHiM5PYYm4IOhLsrKy/I9nzJjBpEmTwlgapfoud5SbJG8SSd6kE35NR2cH9a31VlA011DTXENtS8Dj5lq279vOqpZVNLQ2HPU9EqMTj6hRBNU27NBI9CYSHRUdsc1TGgS9aM+ePeTk5ADw+uuvM2bMETN2KqVOkSvK5f+HPZzhx9y2raON2pbaY4bGxrqN1DTXfG7fhyB4XV68bi9el5cYdwxelxefy3fEOq/Li8/t89/7XIc9dns/f51974nyhCx4NAh6yLRp01i5ciU1NTXk5uby6KOPsnLlStauXYuIkJ+fzzPPPBPuYirlSB6Xh+y47BOake5g20F/aHQFR2NbI60drbS0t9DS3mI97mihtd26b2lvob6tnsqOSmubgOfaOttOqcxREhUUND6Xj2uLruWm0Ted0vsdiwZBD5k/f/4R62655ZYwlEQpdTpiPbHEemLJS8g7/sYnoKOz44jg8IfK0dYdJWi6nkuLSeuRMh1Og0AppXqRK8pFbFRsnz6bSQcgUUoph4uYILCmN3AmJ393pdTpi4gg8Pl81NbWOvIfojGG2tpafD5fuIuilOqnIqKPIDc3l507d1JdXR3uooSFz+cjNzc33MVQSvVTEREEHo+HgoKCcBdDKaX6pYhoGlJKKXXqNAiUUsrhNAiUUsrhpL+daSMi1UD5Kb48HajpweL0d7o/gun+6Kb7Ilgk7I/BxpiMoz3R74LgdIjI/xljzj7+ls6g+yOY7o9uui+CRfr+0KYhpZRyOA0CpZRyOKcFwdxwF6CP0f0RTPdHN90XwSJ6fziqj0AppdSRnFYjUEopdRgNAqWUcjjHBIGIXCEin4rIVhGZHe7yhJKI5InIOyKyUUQ+EZG77PWpIrJcRD6z71PCXdZQEhGXiKwRkcX2coGIfGgfIwtEJDrcZQwVEUkWkT+JyGYR2SQi5zv1+BCR79t/JxtEZL6I+CL92HBEEIiIC/gdcCUwCpgmIqPCW6qQagfuMcaMAs4D7rC//2zgbWPMMOBte9lJ7gI2BSz/DHjCGDMUqAecNNfofwJLjTEjgHFY+8Vxx4eIDATuBM42xowBXMBUIvzYcEQQAOcAW40x240xh4BXgOIwlylkjDF7jDH/tB83Yv2RD8TaB/9jb/Y/wDfCU8LQE5Fc4OvAf9nLAlwK/MnexDH7Q0SSgAnAHwCMMYeMMftw7vHhBmJExA3EAnuI8GPDKUEwENgRsLzTXuc4IpIPfAH4EMgyxuyxn6oEssJUrHD4NXA/0GkvpwH7jDHt9rKTjpECoBr4b7up7L9EJA4HHh/GmF3AL4AKrABoAD4iwo8NpwSBAkQkHlgI3G2M2R/4nLHOI3bEucQiMgmoMsZ8FO6y9BFu4CzgaWPMF4AmDmsGcsrxYfeDFGOF4wAgDrgirIUKAacEwS4gL2A5117nGCLiwQqBl4wxr9mr94pIjv18DlAVrvKF2IXA1SJShtVMeClWG3my3RwAzjpGdgI7jTEf2st/wgoGJx4flwOlxphqY0wb8BrW8RLRx4ZTgmA1MMzu+Y/G6vwpCXOZQsZu//4DsMkY86uAp0qAm+zHNwGLQl22cDDGPGCMyTXG5GMdCyuMMTcA7wDX2ps5aX9UAjtEZLi96jJgI848PiqA80Qk1v676doXEX1sOObKYhGZiNUu7AKeNcb8JMxFChkRuQh4H/iY7jbxB7H6CV4FBmEN7X2dMaYuLIUMExG5BLjXGDNJRAqxagipwBrgRmNMazjLFyoiciZWx3k0sB34LtYPRccdHyLyKDAF62y7NcB0rD6BiD02HBMESimljs4pTUNKKaU+hwaBUko5nAaBUko5nAaBUko5nAaBUko5nAaBciwR+Zt9ny8i1/fwez94tM9Sqi/S00eV4wVeS3ASr3EHjD1ztOcPGGPie6J8SvU2rREoxxKRA/bDnwIXi8haeyx6l4g8LiKrRWS9iNxmb3+JiLwvIiVYV5siIn8WkY/s8etvtdf9FGv0yrUi8lLgZ4nlcXus+49FZErAe68MmBPgJfvKVqV6nfv4mygV8WYTUCOw/6E3GGPGi4gX+KuILLO3PQsYY4wptZdvNsbUiUgMsFpEFhpjZovILGPMmUf5rG8CZ2KN+Z9uv+Y9+7kvAKOB3cBfsca4+aDnv65SwbRGoNSRvgp8W0TWYg3DkQYMs59bFRACAHeKyDrgH1gDGw7j2C4C5htjOowxe4F3gfEB773TGNMJrAXye+TbKHUcWiNQ6kgCfM8Y82bQSqsvoemw5cuB840xB0VkJeA7jc8NHLumA/37VCGiNQKloBFICFh+E5hpD92NiBTZE7UcLgmot0NgBNY0oF3aul5/mPeBKXY/RAbWzGCreuRbKHWK9BeHUrAe6LCbeJ7DmpsgH/in3WFbzdGnJlwK3C4im4BPsZqHuswF1ovIP+0hrru8DpwPrMOa6OV+Y0ylHSRKhYWePqqUUg6nTUNKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVwGgRKKeVw/w/IhL+5KGO9SgAAAABJRU5ErkJggg==)\n",
        "\n",
        "\n",
        "$$$$\n",
        "Discussion:\n",
        "As we can see, when the learning rate is too big, there is a high overshoot due to large step size, and when it too small, it does converge but really really slowly as we've learned in class. we can see when using 100 iteration and batch size of 10, the proper value of the step size is around $\\frac{1}{2}$. \n",
        "The algorithm of SGD is calculating gradient at each iteration , so when the step size is too big , it can \"throw\" you away from the minimum , so it will increase the gradiant even more in the next iteration.\n"
      ],
      "metadata": {
        "id": "U7ydPBsFi7T9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (g)"
      ],
      "metadata": {
        "id": "eeH7NBF3r9h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "# Write your code here\n",
        "resulteArray=[[] for i in range(1,11)]\n",
        "for m in range(1,11):\n",
        "  for batch in range(1,11):\n",
        "    w,b,costRun=run_gradient_descent(w0,b0,mu=m*0.1,batch_size=10*batch)\n",
        "    resulteArray[m].append([w,b,costRun[-1],m*0.1,batch*10])\n",
        "resulteArray.sort(key=lambda x:x[2])  #now it 2d array maybe need to change\n",
        "#plot 3d graph?\n",
        "print(resulteArray[0])\n"
      ],
      "metadata": {
        "id": "EqRSPo06sB7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain and discuss your results here:**\n"
      ],
      "metadata": {
        "id": "LdGp7EOG6ugo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try_this=myplace  #need to delete this i think"
      ],
      "metadata": {
        "id": "kHOB07Ii3ThK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dont need this?\n",
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "N = len(try_this)\n",
        "mu=[try_this[0][-2], try_this[N//4][-2], try_this[N//2][-2], try_this[3*N//4][-2]]\n",
        "batch=[try_this[0][-1], try_this[N//4][-1], try_this[N//2][-1], try_this[3*N//4][-1]]\n",
        "run_cost=[[] for i in range(len(mu))]\n",
        "run_acc=[[] for i in range(len(mu))]\n",
        "# Write your code here\n",
        "i =0\n",
        "for u,b in zip(mu,batch):\n",
        "  _,_,costRun,accRun=run_gradient_descent(train_xs,train_ts,train_norm_xs,w0,b0,u,b)\n",
        "  run_cost[i]=costRun\n",
        "  run_acc[i]=accRun\n",
        "  i+=1\n",
        "\n",
        "for m in range(len(mu)):\n",
        "  plt.plot([10*i for i in range(len(run_cost[m]))],run_cost[m])\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.legend([\"u={0},batch={1}\".format(round(mu[0],4),batch[0]),\"u={0},batch={1}\".format(round(mu[1],4),batch[1]),\"u={0},batch={1}\".format(round(mu[2],4),batch[2]),\"u={0},batch={1}\".format(round(mu[3],4),batch[3])])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dTYDI4hVy_tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (h)"
      ],
      "metadata": {
        "id": "qHAeY0559AbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "w=try_this[0][0]\n",
        "b=try_this[0][1]\n",
        "\n",
        "pred_train=pred(w,b,train_norm_xs)\n",
        "pred_val=pred(w,b,val_norm_xs)\n",
        "pred_test=pred(w,b,test_norm_xs)\n",
        "\n",
        "train_acc = get_accuracy(pred_train,train_ts)\n",
        "val_acc = get_accuracy(pred_val,val_ts)\n",
        "test_acc = get_accuracy(pred_test,test_ts)\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "metadata": {
        "id": "EO0P_E1G8_ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "As we could guesses, there is a difference between the accuracies, because Every one of the accuricies was calculated on different and unique data set. \n",
        "But they are very familliar, because our model predicted successfully the probability rule of the data."
      ],
      "metadata": {
        "id": "19HwaBEi_SiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part (i)"
      ],
      "metadata": {
        "id": "lJAOAmoQAy5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = sklearn.linear_model.LogisticRegression()\n",
        "model.fit(train_norm_xs,train_ts)\n",
        "\n",
        "pred_train=model.predict(train_norm_xs)\n",
        "pred_val=model.predict(val_norm_xs)\n",
        "pred_test=model.predict(test_norm_xs)\n",
        "\n",
        "train_acc = get_accuracy(pred_train,train_ts)\n",
        "val_acc = get_accuracy(pred_val,val_ts)\n",
        "test_acc = get_accuracy(pred_test,test_ts)\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "metadata": {
        "id": "zyJUz0q4AyEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}